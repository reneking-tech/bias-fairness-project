{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Weighted Data\n",
    "\n",
    "In this notebook, we train a machine learning model using the weighted data generated in the bias mitigation step. We will:\n",
    "- Load the weighted dataset (`weighted_train.csv`)\n",
    "- Split the data into training and testing sets\n",
    "- Scale the features using StandardScaler\n",
    "- Train a Logistic Regression model as our baseline classifier\n",
    "- Evaluate the model's performance with accuracy and a classification report\n",
    "\n",
    "Let's begin by setting up our environment and defining the file paths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading\n",
    "\n",
    "We first construct the absolute path to the weighted data file. Since the notebook is in the `notebooks` folder, we move up one level to locate the project root. Then we load the weighted dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: /Users/stay-c/Desktop/AI_Fairness_Project\n",
      "Looking for weighted data at: /Users/stay-c/Desktop/AI_Fairness_Project/data/weighted_train.csv\n",
      "Weighted data loaded. Shape: (32561, 15)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# In a notebook, __file__ is not defined. We use os.getcwd() and move up one level if necessary.\n",
    "current_dir = os.getcwd()\n",
    "if os.path.basename(current_dir) == \"notebooks\":\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "print(\"Project root directory:\", project_root)\n",
    "\n",
    "# Construct the absolute path to the weighted data file.\n",
    "weighted_csv_path = os.path.join(project_root, \"data\", \"weighted_train.csv\")\n",
    "print(\"Looking for weighted data at:\", weighted_csv_path)\n",
    "\n",
    "# Check if the weighted data file exists.\n",
    "if not os.path.exists(weighted_csv_path):\n",
    "    sys.exit(f\"Error: Weighted data file not found at {weighted_csv_path}.\\n\"\n",
    "             \"Please run the bias_mitigation script to generate weighted_train.csv before proceeding.\")\n",
    "\n",
    "# Load the weighted data.\n",
    "weighted_df = pd.read_csv(weighted_csv_path)\n",
    "print(\"Weighted data loaded. Shape:\", weighted_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Next, we prepare our data for model training:\n",
    "- We assume the target column is named `income_binary`.\n",
    "- We separate the features (X) from the target (y).\n",
    "- Then, we split the data into training and testing sets using a 70-30 split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure the target column exists.\n",
    "if 'income_binary' not in weighted_df.columns:\n",
    "    sys.exit(\"Error: Expected target column 'income_binary' not found in weighted data.\")\n",
    "\n",
    "# Separate features and target.\n",
    "X = weighted_df.drop(['income_binary'], axis=1)\n",
    "y = weighted_df['income_binary']\n",
    "\n",
    "# Split data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Weighted data split into training and testing sets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling and Model Training\n",
    "\n",
    "Feature scaling is important to ensure that all input features have equal weight during model training.  \n",
    "In this cell, we:\n",
    "- Scale the features using StandardScaler.\n",
    "- Train a Logistic Regression model on the scaled training data.\n",
    "- Evaluate the model performance on the test data using accuracy and a classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on weighted data.\n",
      "Weighted Model Accuracy: 0.8258777766403931\n",
      "Weighted Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89      7455\n",
      "         1.0       0.71      0.45      0.55      2314\n",
      "\n",
      "    accuracy                           0.83      9769\n",
      "   macro avg       0.78      0.70      0.72      9769\n",
      "weighted avg       0.81      0.83      0.81      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scale features using StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model on the weighted data.\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model trained on weighted data.\")\n",
    "\n",
    "# Evaluate model performance on the test set.\n",
    "predictions = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Weighted Model Accuracy:\", accuracy)\n",
    "print(\"Weighted Model Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we:\n",
    "- Set up the environment and correctly located the weighted data file.\n",
    "- Prepared the data by separating features and target, then splitting it into training and testing sets.\n",
    "- Scaled the features and trained a Logistic Regression model on the weighted data.\n",
    "- Evaluated the model, obtaining accuracy and detailed classification metrics.\n",
    "\n",
    "This model will serve as our baseline for comparing performance and fairness in subsequent evaluations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
